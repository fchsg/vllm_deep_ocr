# run_gradio.py
# æ³¨æ„ï¼šæ›¿æ¢æœ¬æ–‡ä»¶ä¼šå¯åŠ¨ Gradio æœåŠ¡ï¼Œç¡®ä¿ä¾èµ–å·²å®‰è£…
# pip install gradio transformers torch pillow pylatexenc

import gradio as gr
from transformers import AutoModel, AutoTokenizer
import torch
import os
from PIL import Image
import tempfile
import shutil
import io
import base64

# pylatexenc ç”¨äº LaTeX è½¬æ–‡æœ¬
try:
    from pylatexenc.latex2text import LatexNodes2Text
except Exception as _e:
    print("pylatexenc æœªå®‰è£…ï¼Œè¯·å…ˆæ‰§è¡Œ: pip install pylatexenc")

# Global variables for model and tokenizer
model = None
tokenizer = None


def load_model():
    """Load the DeepSeek-OCR model and tokenizer"""
    global model, tokenizer

    if model is None:
        print("Loading DeepSeek-OCR model...")
        model_name = 'deepseek-ai/DeepSeek-OCR'

        tokenizer = AutoTokenizer.from_pretrained(model_name, trust_remote_code=True)
        model = AutoModel.from_pretrained(
            model_name,
            _attn_implementation='flash_attention_2',
            trust_remote_code=True,
            use_safetensors=True
        )
        model = model.eval().cuda().to(torch.bfloat16)
        print("Model loaded successfully!")

    return model, tokenizer


def latex_to_readable_text(latex_str: str) -> str:
    """
    ä½¿ç”¨ pylatexenc å°† LaTeX è½¬æ¢ä¸ºå¯è¯»çº¯æ–‡æœ¬ã€‚
    å¦‚æœ pylatexenc ä¸å¯ç”¨æˆ–è½¬æ¢å¤±è´¥ï¼Œè¿”å›åŸæ–‡ã€‚
    """
    if not latex_str or not latex_str.strip():
        return latex_str
    try:
        return LatexNodes2Text().latex_to_text(latex_str)
    except Exception:
        return latex_str


def pil_image_to_base64_datauri(img: Image.Image, max_width=1200, quality=85, fmt="JPEG"):
    """
    å°† PIL Image è½¬ä¸º base64 data URIï¼ˆé»˜è®¤ JPEGï¼‰ã€‚
    - max_width: è‹¥å›¾ç‰‡å®½åº¦å¤§äºè¯¥å€¼ï¼Œå°†æŒ‰æ¯”ä¾‹ç¼©æ”¾
    - quality: JPEG å‹ç¼©è´¨é‡ï¼ˆ0-100ï¼‰
    è¿”å› data uri å­—ç¬¦ä¸²ï¼Œä¾‹å¦‚ "data:image/jpeg;base64,...."
    """
    if img is None:
        return None
    try:
        w, h = img.size
    except Exception:
        return None

    # ç¼©æ”¾ï¼ˆä»…å®½åº¦ï¼‰
    if max_width and w > max_width:
        new_w = max_width
        new_h = int(h * (new_w / w))
        img = img.resize((new_w, new_h), Image.LANCZOS)

    img_format = fmt.upper()
    buf = io.BytesIO()
    save_kwargs = {}
    if img_format == "JPEG":
        if img.mode in ("RGBA", "LA"):
            background = Image.new("RGB", img.size, (255, 255, 255))
            # ä½¿ç”¨ alpha é€šé“ä½œä¸º mask
            background.paste(img, mask=img.split()[3])
            img_to_save = background
        else:
            img_to_save = img.convert("RGB")
        save_kwargs["quality"] = quality
    else:
        img_to_save = img

    img_to_save.save(buf, format=img_format, **save_kwargs)
    b = buf.getvalue()
    encoded = base64.b64encode(b).decode("ascii")
    mime = "image/jpeg" if img_format == "JPEG" else f"image/{img_format.lower()}"
    return f"data:{mime};base64,{encoded}"


def build_markdown_with_image(readable_text: str, image_obj, embed_base64=True, max_width=1200, quality=85):
    """
    ç”ŸæˆåŒ…å« OCR æ–‡æœ¬ä¸ OCR ç»“æœå›¾ç‰‡çš„ Markdownã€‚
    - readable_text: OCR å¯è¯»æ–‡æœ¬
    - image_obj: PIL.Image æˆ– è·¯å¾„
    - embed_base64: æ˜¯å¦å°†å›¾ç‰‡ä»¥ data URI å½¢å¼åµŒå…¥ Markdownï¼ˆé»˜è®¤ Trueï¼‰
    """
    md_parts = []
    md_parts.append("# OCR ç»“æœ")
    md_parts.append("")
    md_parts.append("## æ–‡æœ¬")
    md_parts.append("")
    md_parts.append(readable_text if readable_text else "*æœªè¯†åˆ«åˆ°æ–‡æœ¬*")
    md_parts.append("")
    md_parts.append("## OCR ç»“æœå›¾ç‰‡")
    md_parts.append("")

    if image_obj is None:
        md_parts.append("_æ—  OCR è¾“å‡ºå›¾ç‰‡_")
    else:
        if embed_base64:
            try:
                if isinstance(image_obj, str) and os.path.exists(image_obj):
                    pil_img = Image.open(image_obj)
                else:
                    pil_img = image_obj  # æœŸæœ›æ˜¯ PIL.Image
                data_uri = pil_image_to_base64_datauri(pil_img, max_width=max_width, quality=quality)
                if data_uri:
                    md_parts.append(f"![OCR ç»“æœ]({data_uri})")
                else:
                    md_parts.append("![OCR ç»“æœ](input_image.jpg)")
            except Exception:
                md_parts.append("![OCR ç»“æœ](input_image.jpg)")
        else:
            md_parts.append("![OCR ç»“æœ](input_image.jpg)")

    md_parts.append("")
    return "\n".join(md_parts)


def export_markdown(markdown_text: str, image_obj, embed_base64=True, max_width=1200, quality=85):
    """
    å¯¼å‡º Markdownï¼Œå¹¶è¿”å›å¯ä¾› gr.File ä¸‹è½½çš„è·¯å¾„ã€‚
    - embed_base64 True: .md ä¸­å·²åŒ…å«å›¾ç‰‡ (data URI)
    - embed_base64 False: ä¼šå°†å›¾ç‰‡ä¿å­˜ä¸º input_image.jpg ä¸ result.md åŒç›®å½•
    è¿”å› md æ–‡ä»¶çš„ç»å¯¹è·¯å¾„æˆ– None
    """
    try:
        temp_dir = tempfile.mkdtemp()
        md_path = os.path.join(temp_dir, "result.md")

        if not embed_base64 and image_obj is not None:
            img_path = os.path.join(temp_dir, "input_image.jpg")
            try:
                if isinstance(image_obj, str) and os.path.exists(image_obj):
                    shutil.copy(image_obj, img_path)
                else:
                    image_obj.save(img_path)
            except Exception as e:
                print(f"ä¿å­˜å›¾ç‰‡å¤±è´¥: {e}")

        with open(md_path, "w", encoding="utf-8") as f:
            f.write(markdown_text or "")

        return md_path
    except Exception as e:
        print(f"å¯¼å‡ºå¤±è´¥: {e}")
        return None


def find_result_image_in_dir(dir_path):
    """
    åœ¨æ¨¡å‹è¾“å‡ºç›®å½•ä¸­æŸ¥æ‰¾ä»£è¡¨ OCR ç»“æœçš„å›¾ç‰‡æ–‡ä»¶ã€‚
    ç­–ç•¥ï¼š
      - æœç´¢å¸¸è§å›¾åƒæ‰©å±• (.png, .jpg, .jpeg)
      - ä¼˜å…ˆé€‰æ‹©æ–‡ä»¶ååŒ…å« 'result' æˆ– 'vis' æˆ– 'output' çš„æ–‡ä»¶
      - å¦åˆ™è¿”å›ç¬¬ä¸€ä¸ªæ‰¾åˆ°çš„å›¾åƒ
    è¿”å›ï¼šPIL.Image å¯¹è±¡æˆ– None
    """
    exts = ('.png', '.jpg', '.jpeg', '.webp')
    candidates = []
    for fname in os.listdir(dir_path):
        if fname.lower().endswith(exts):
            candidates.append(fname)

    if not candidates:
        return None

    # ä¼˜å…ˆçº§æ’åº
    preferred_keywords = ['result', 'vis', 'output', 'pred', 'ocr']
    def score(name):
        n = name.lower()
        s = 0
        for i, kw in enumerate(preferred_keywords):
            if kw in n:
                s += (len(preferred_keywords) - i) * 10
        # ç•¥å¾®ä¼˜å…ˆè¾ƒå¤§çš„æ–‡ä»¶ï¼ˆå¯èƒ½åŒ…å«å¯è§†åŒ–ï¼‰
        try:
            p = os.path.getsize(os.path.join(dir_path, name))
            s += int(p / 1024)  # å¤§æ–‡ä»¶å¾—åˆ†æ›´é«˜
        except Exception:
            pass
        return s

    candidates.sort(key=lambda x: score(x), reverse=True)
    best = candidates[0]
    try:
        img_path = os.path.join(dir_path, best)
        pil_img = Image.open(img_path).convert("RGB")
        return pil_img
    except Exception:
        return None


def process_image(image, prompt_type, custom_prompt, model_size):
    """
    Process image with OCR and return:
      - readable_text: ä½¿ç”¨ pylatexenc è½¬æ¢åçš„å¯è¯»æ–‡æœ¬ï¼ˆç›´æ¥æ˜¾ç¤ºåœ¨ Resultsï¼‰
      - result_img: PIL.Imageï¼ˆOCR ç»“æœå¯è§†åŒ–å›¾ç‰‡æˆ–åŸå§‹ä¸Šä¼ å›¾ç‰‡ï¼‰
    """
    try:
        model, tokenizer = load_model()

        temp_dir = tempfile.mkdtemp()

        # ä¿å­˜ä¸Šä¼ çš„è¾“å…¥å›¾åƒ
        temp_image_path = os.path.join(temp_dir, "input_image.jpg")
        if isinstance(image, str):
            shutil.copy(image, temp_image_path)
            input_pil = Image.open(temp_image_path).convert("RGB")
        else:
            image.save(temp_image_path)
            input_pil = image.convert("RGB")

        # æ„å»º prompt
        if prompt_type == "Free OCR":
            prompt = "<image>\nFree OCR. "
        elif prompt_type == "Markdown Conversion":
            prompt = "<image>\n<|grounding|>Convert the document to markdown. "
        elif prompt_type == "Custom":
            prompt = f"<image>\n{custom_prompt}"
        else:
            prompt = "<image>\nFree OCR. "

        size_configs = {
            "Tiny": {"base_size": 512, "image_size": 512, "crop_mode": False},
            "Small": {"base_size": 640, "image_size": 640, "crop_mode": False},
            "Base": {"base_size": 1024, "image_size": 1024, "crop_mode": False},
            "Large": {"base_size": 1280, "image_size": 1280, "crop_mode": False},
            "Gundam (Recommended)": {"base_size": 1024, "image_size": 640, "crop_mode": True}
        }

        config = size_configs.get(model_size, size_configs["Gundam (Recommended)"])

        # æ•è· stdout
        import sys
        from io import StringIO
        old_stdout = sys.stdout
        sys.stdout = captured_output = StringIO()

        try:
            result = model.infer(
                tokenizer,
                prompt=prompt,
                image_file=temp_image_path,
                output_path=temp_dir,
                base_size=config["base_size"],
                image_size=config["image_size"],
                crop_mode=config["crop_mode"],
                save_results=True,
                test_compress=False
            )
        finally:
            sys.stdout = old_stdout

        captured_text = captured_output.getvalue()

        # å°è¯•è¯»å–è¾“å‡ºç›®å½•ä¸­çš„æ–‡æœ¬æ–‡ä»¶ï¼ˆä¼˜å…ˆï¼‰
        ocr_text = ""
        for filename in os.listdir(temp_dir):
            if filename.endswith('.txt'):
                try:
                    with open(os.path.join(temp_dir, filename), 'r', encoding='utf-8') as f:
                        ocr_text += f.read() + "\n"
                except Exception:
                    pass

        # å¦‚æœæ²¡æœ‰æ–‡æœ¬æ–‡ä»¶ï¼Œè§£æ captured_text
        if not ocr_text.strip() and captured_text.strip():
            lines = captured_text.split('\n')
            clean_lines = []
            for line in lines:
                if '<|ref|>' in line or '<|det|>' in line or '<|/ref|>' in line or '<|/det|>' in line:
                    import re
                    text_match = re.search(r'<\|/ref\|>(.*?)<\|det\|>', line)
                    if text_match:
                        clean_lines.append(text_match.group(1).strip())
                elif line.startswith('=====') or 'BASE:' in line or 'PATCHES:' in line or line.startswith('image:') or line.startswith('other:'):
                    continue
                elif line.strip():
                    clean_lines.append(line.strip())
            ocr_text = "\n".join(clean_lines)

        if not ocr_text.strip():
            # å¦‚æœ result æ˜¯å­—ç¬¦ä¸²ï¼Œå¯èƒ½ç›´æ¥è¿”å›æ–‡æœ¬
            if isinstance(result, str):
                ocr_text = result
            else:
                ocr_text = ""

        # å°† OCR æ–‡æœ¬ï¼ˆå¯èƒ½ä¸º LaTeXï¼‰è½¬æ¢ä¸ºå¯è¯»æ–‡æœ¬
        readable = latex_to_readable_text(ocr_text) if ocr_text else ""

        # æŸ¥æ‰¾æ¨¡å‹ç”Ÿæˆçš„ç»“æœå›¾ç‰‡ï¼ˆä¼˜å…ˆï¼‰ï¼Œè‹¥æ— åˆ™ä½¿ç”¨è¾“å…¥å›¾ç‰‡
        result_img = find_result_image_in_dir(temp_dir)
        if result_img is None:
            result_img = input_pil

        # å°†å›¾ç‰‡åŠ è½½åˆ°å†…å­˜åå¯ä»¥åˆ é™¤ä¸´æ—¶ç›®å½•
        # result_img å·²ç»æ˜¯ PIL.Image å¯¹è±¡
        try:
            shutil.rmtree(temp_dir)
        except Exception:
            pass

        # è¿”å› readable text ä¸ PIL image
        return readable if readable.strip() else "No text detected in image.", result_img

    except Exception as e:
        import traceback
        msg = f"Error: {str(e)}\n\nTraceback:\n{traceback.format_exc()}\n\nPlease make sure you have a CUDA-enabled GPU and all dependencies installed."
        # è¿”å›é”™è¯¯ä¿¡æ¯ä¸ç©ºå›¾ç‰‡
        return msg, None


def create_demo():
    """Create Gradio interface"""

    with gr.Blocks(title="DeepSeek-OCR Demo", theme=gr.themes.Soft()) as demo:
        gr.Markdown(
            """
            # ğŸ” DeepSeek-OCR

            Upload an image containing text, documents, charts, or tables to extract text using DeepSeek-OCR.

            **Features:**
            - Free OCR for general text extraction
            - Markdown conversion for document structure
            - Multiple model sizes for different accuracy/speed tradeoffs
            - Support for various document types
            """
        )

        with gr.Row():
            with gr.Column(scale=1):
                # Input section
                gr.Markdown("### ğŸ“¤ Input")
                image_input = gr.Image(
                    label="Upload Image",
                    type="pil",
                    sources=["upload", "clipboard"]
                )

                gr.Markdown("### âš™ï¸ Settings")

                prompt_type = gr.Radio(
                    choices=["Free OCR", "Markdown Conversion", "Custom"],
                    value="Markdown Conversion",
                    label="Prompt Type",
                    info="Choose the type of OCR processing"
                )

                custom_prompt = gr.Textbox(
                    label="Custom Prompt (if selected)",
                    placeholder="Enter your custom prompt here...",
                    lines=2,
                    visible=False
                )

                model_size = gr.Radio(
                    choices=[
                        "Tiny",
                        "Small",
                        "Base",
                        "Large",
                        "Gundam (Recommended)"
                    ],
                    value="Gundam (Recommended)",
                    label="Model Size",
                    info="Larger models are more accurate but slower"
                )

                process_btn = gr.Button("ğŸš€ Process Image", variant="primary", size="lg")

                gr.Markdown(
                    """
                    ### ğŸ’¡ Tips
                    - **Gundam** mode works best for most documents
                    - Use **Markdown Conversion** for structured documents
                    - **Free OCR** for simple text extraction
                    - Higher resolution images give better results
                    """
                )

            with gr.Column(scale=1):
                # Output section
                gr.Markdown("### ğŸ“„ Results")
                output_text = gr.Textbox(
                    label="Extracted Text (readable)",
                    lines=20,
                    max_lines=30,
                    show_copy_button=True
                )
                result_image = gr.Image(
                    label="Result Image (OCR output)",
                    type="pil"
                )

                # æ–°å¢ï¼šLaTeX è½¬æ–‡æœ¬ + Markdown ç”Ÿæˆ/å¯¼å‡º
                gr.Markdown("### ğŸ“ Markdown")
                readable_toggle = gr.Checkbox(
                    label="å°† LaTeX è½¬æ¢ä¸ºå¯è¯»æ–‡æœ¬ï¼ˆpylatexencï¼‰",
                    value=True,
                    info="å¼€å¯åå°†ä½¿ç”¨ pylatexenc æŠŠ LaTeX è½¬ä¸ºæ™®é€šæ–‡æœ¬ï¼ˆResults å·²ç»è¿”å›å¯è¯»æ–‡æœ¬ï¼‰"
                )
                embed_toggle = gr.Checkbox(
                    label="åœ¨ Markdown ä¸­åµŒå…¥å›¾ç‰‡ï¼ˆBase64ï¼‰",
                    value=True,
                    info="å¼€å¯åå›¾ç‰‡ä¼šä»¥ base64 data URI åµŒå…¥ Markdownï¼Œå‰ç«¯å¯ä»¥ç›´æ¥é¢„è§ˆ"
                )
                generate_md_btn = gr.Button("ğŸ“ ç”Ÿæˆ Markdown", variant="secondary")
                md_preview = gr.Markdown(label="Markdown é¢„è§ˆ", value="")
                export_md_btn = gr.Button("ğŸ’¾ å¯¼å‡º Markdown", variant="secondary")
                md_file = gr.File(label="ä¸‹è½½ç”Ÿæˆçš„ Markdown æ–‡ä»¶", interactive=False)

                gr.Markdown(
                    """
                    ### ğŸ“¥ Export
                    1) ç‚¹å‡»â€œProcess Imageâ€å¾—åˆ° Resultsï¼ˆå¯è¯»æ–‡æœ¬ + OCR å›¾åƒï¼‰
                    2) ç‚¹å‡»â€œç”Ÿæˆ Markdownâ€é¢„è§ˆæ–‡æœ¬ä¸å›¾ç‰‡
                    3) ç‚¹å‡»â€œå¯¼å‡º Markdownâ€ä¿å­˜å¹¶ä¸‹è½½ .md æ–‡ä»¶ï¼ˆåŒ…å«å›¾ç‰‡æˆ–ä¸å›¾ç‰‡é…å¥—ï¼‰
                    """
                )

        # Show/hide custom prompt based on selection
        def update_prompt_visibility(choice):
            return gr.update(visible=(choice == "Custom"))

        prompt_type.change(
            fn=update_prompt_visibility,
            inputs=[prompt_type],
            outputs=[custom_prompt]
        )

        # Process button click -> return readable text and result image
        process_btn.click(
            fn=process_image,
            inputs=[image_input, prompt_type, custom_prompt, model_size],
            outputs=[output_text, result_image]
        )

        # ç”Ÿæˆ Markdown é€»è¾‘ (ä½¿ç”¨ process è¿”å›çš„æ–‡æœ¬ä¸å›¾ç‰‡)
        def to_readable_and_md(text_result, image_obj, use_readable, embed_base64):
            """
            å°†æ–‡æœ¬ï¼ˆResults ä¸­çš„æ–‡æœ¬ï¼‰å’Œ OCR ç»“æœå›¾ç‰‡ç”Ÿæˆ Markdown é¢„è§ˆã€‚
            Note: text_result åœ¨ process_image ä¸­å·²ä¸ºå¯è¯»æ–‡æœ¬ã€‚
            """
            try:
                # å¦‚æœç”¨æˆ·å…³é—­äº† pylatexencï¼Œä½† process_image å·²ç»è½¬äº†ï¼Œç›´æ¥ä½¿ç”¨ text_result
                readable = text_result
                md_str = build_markdown_with_image(readable, image_obj, embed_base64=embed_base64)
                return md_str
            except Exception as e:
                return f"ç”Ÿæˆ Markdown å¤±è´¥ï¼š{e}"

        generate_md_btn.click(
            fn=to_readable_and_md,
            inputs=[output_text, result_image, readable_toggle, embed_toggle],
            outputs=[md_preview]
        )

        # å¯¼å‡º Markdown é€»è¾‘
        def on_export_md(md_str, image_obj, embed_base64):
            file_path = export_markdown(md_str, image_obj, embed_base64=embed_base64)
            return file_path

        export_md_btn.click(
            fn=on_export_md,
            inputs=[md_preview, result_image, embed_toggle],
            outputs=[md_file]
        )

        # Add examples
        gr.Markdown("### ğŸ“š Example Images")
        gr.Examples(
            examples=[
                ["example_document.jpg", "Markdown Conversion", "", "Gundam (Recommended)"],
                ["example_receipt.jpg", "Free OCR", "", "Small"],
            ],
            inputs=[image_input, prompt_type, custom_prompt, model_size],
            outputs=[output_text, result_image],
            fn=process_image,
            cache_examples=False,
        )

        gr.Markdown(
            """
            ---
            ### â„¹ï¸ About

            This demo uses [DeepSeek-OCR](https://huggingface.co/deepseek-ai/DeepSeek-OCR) for optical character recognition.

            **Model Sizes Explained:**
            - **Tiny**: Fastest, lowest accuracy (512x512)
            - **Small**: Fast, good for simple documents (640x640)
            - **Base**: Balanced performance (1024x1024)
            - **Large**: High accuracy, slower (1280x1280)
            - **Gundam (Recommended)**: Balanced config with crop mode for complex docs
            """
        )

    return demo


if __name__ == "__main__":
    demo = create_demo()
    demo.launch(server_name="0.0.0.0", server_port=7860, share=False)
