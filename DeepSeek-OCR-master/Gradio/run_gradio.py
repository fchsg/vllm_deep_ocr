# ç¡®ä¿å®‰è£…äº†gradioï¼Œç”¨pip install gradio

import gradio as gr
from transformers import AutoModel, AutoTokenizer
import torch
import os
from PIL import Image
import tempfile
import shutil

# pylatexenc ç”¨äº LaTeX è½¬æ–‡æœ¬
try:
    from pylatexenc.latex2text import LatexNodes2Text
except Exception as _e:
    print("pylatexenc æœªå®‰è£…ï¼Œè¯·å…ˆæ‰§è¡Œ: pip install pylatexenc")

# Global variables for model and tokenizer
model = None
tokenizer = None


def load_model():
    """Load the DeepSeek-OCR model and tokenizer"""
    global model, tokenizer

    if model is None:
        print("Loading DeepSeek-OCR model...")
        model_name = 'deepseek-ai/DeepSeek-OCR'

        tokenizer = AutoTokenizer.from_pretrained(model_name, trust_remote_code=True)
        model = AutoModel.from_pretrained(
            model_name,
            _attn_implementation='flash_attention_2',
            trust_remote_code=True,
            use_safetensors=True
        )
        model = model.eval().cuda().to(torch.bfloat16)
        print("Model loaded successfully!")

    return model, tokenizer


def process_image(image, prompt_type, custom_prompt, model_size):
    """Process image with OCR"""
    try:
        # Load model if not already loaded
        model, tokenizer = load_model()

        # Create temporary directory for output
        temp_dir = tempfile.mkdtemp()

        # Save uploaded image temporarily
        temp_image_path = os.path.join(temp_dir, "input_image.jpg")
        if isinstance(image, str):
            shutil.copy(image, temp_image_path)
        else:
            image.save(temp_image_path)

        # Set prompt based on selection
        if prompt_type == "Free OCR":
            prompt = "<image>\nFree OCR. "
        elif prompt_type == "Markdown Conversion":
            prompt = "<image>\n<|grounding|>Convert the document to markdown. "
        elif prompt_type == "Custom":
            prompt = f"<image>\n{custom_prompt}"
        else:
            prompt = "<image>\nFree OCR. "

        # Set model size parameters
        size_configs = {
            "Tiny": {"base_size": 512, "image_size": 512, "crop_mode": False},
            "Small": {"base_size": 640, "image_size": 640, "crop_mode": False},
            "Base": {"base_size": 1024, "image_size": 1024, "crop_mode": False},
            "Large": {"base_size": 1280, "image_size": 1280, "crop_mode": False},
            "Gundam (Recommended)": {"base_size": 1024, "image_size": 640, "crop_mode": True}
        }

        config = size_configs[model_size]

        # Capture stdout to get the OCR results
        import sys
        from io import StringIO

        # Redirect stdout to capture print statements
        old_stdout = sys.stdout
        sys.stdout = captured_output = StringIO()

        try:
            # Run inference
            result = model.infer(
                tokenizer,
                prompt=prompt,
                image_file=temp_image_path,
                output_path=temp_dir,
                base_size=config["base_size"],
                image_size=config["image_size"],
                crop_mode=config["crop_mode"],
                save_results=True,
                test_compress=False
            )
        finally:
            # Restore stdout
            sys.stdout = old_stdout

        # Get captured output
        captured_text = captured_output.getvalue()

        # Try to read from saved text file if it exists
        ocr_text = ""
        for filename in os.listdir(temp_dir):
            if filename.endswith('.txt'):
                with open(os.path.join(temp_dir, filename), 'r', encoding='utf-8') as f:
                    ocr_text += f.read() + "\n"

        # If we found text in files, use that; otherwise use captured output
        if ocr_text.strip():
            final_result = ocr_text.strip()
        elif captured_text.strip():
            # Parse the captured output to extract actual OCR text
            # Remove detection boxes and reference tags
            lines = captured_text.split('\n')
            clean_lines = []
            for line in lines:
                # Skip lines with detection boxes and reference tags
                if '<|ref|>' in line or '<|det|>' in line or '<|/ref|>' in line or '<|/det|>' in line:
                    # Extract text between tags
                    import re
                    # Pattern to match text between </ref|> and <|det|>
                    text_match = re.search(r'<\|/ref\|>(.*?)<\|det\|>', line)
                    if text_match:
                        clean_lines.append(text_match.group(1).strip())
                elif line.startswith('=====') or 'BASE:' in line or 'PATCHES:' in line or line.startswith(
                        'image:') or line.startswith('other:'):
                    continue
                elif line.strip():
                    clean_lines.append(line.strip())

            final_result = '\n'.join(clean_lines)
        elif isinstance(result, str):
            final_result = result
        else:
            final_result = str(result) if result else "No text detected in image."

        # Clean up temporary directory
        shutil.rmtree(temp_dir)

        return final_result if final_result.strip() else "No text detected in image."

    except Exception as e:
        import traceback
        return f"Error: {str(e)}\n\nTraceback:\n{traceback.format_exc()}\n\nPlease make sure you have a CUDA-enabled GPU and all dependencies installed."


# =========================
# æ–°å¢ï¼šLaTeX è½¬æ–‡æœ¬ä¸ Markdown æ„å»º/å¯¼å‡ºå·¥å…·å‡½æ•°
# =========================
def latex_to_readable_text(latex_str: str) -> str:
    """
    ä½¿ç”¨ pylatexenc å°† LaTeX è½¬æ¢ä¸ºå¯è¯»çº¯æ–‡æœ¬ã€‚
    å¦‚æœ pylatexenc ä¸å¯ç”¨æˆ–è½¬æ¢å¤±è´¥ï¼Œè¿”å›åŸæ–‡ã€‚
    """
    if not latex_str or not latex_str.strip():
        return latex_str
    try:
        return LatexNodes2Text().latex_to_text(latex_str)
    except Exception:
        return latex_str


def build_markdown_with_image(readable_text: str, image_obj) -> str:
    """
    ç”ŸæˆåŒ…å«æ–‡æœ¬ä¸å›¾ç‰‡çš„ Markdownã€‚
    - readable_text: å·²è½¬æ¢ä¸ºå¯è¯»æ–‡æœ¬çš„ç»“æœ
    - image_obj: æ¥è‡ª gr.Image çš„ PIL Image æˆ–è€…è·¯å¾„
    ç­–ç•¥ï¼š
      1) è‡³å°‘åµŒå…¥ç”¨æˆ·ä¸Šä¼ çš„å›¾ç‰‡ï¼Œæ»¡è¶³â€œå¦‚æœå¤„ç†çš„å›¾ç‰‡ä¸­åŒ…å«å›¾ç‰‡ï¼Œè¿”å›markdownä¸­éœ€è¦åŒ…å«å›¾ç‰‡â€ã€‚
      2) è‹¥åç»­éœ€è¦æ’å…¥æ–‡æ¡£å†…éƒ¨å›¾ç‰‡ï¼Œè¯·åœ¨ infer é˜¶æ®µä¿ç•™å›¾ç‰‡åˆ—è¡¨ä¸ä½ç½®ä¿¡æ¯å†æ‰©å±•ã€‚
    """
    md_parts = []
    md_parts.append("# OCR ç»“æœ")
    md_parts.append("")
    md_parts.append("## æ–‡æœ¬")
    md_parts.append("")
    md_parts.append(readable_text if readable_text else "*æœªè¯†åˆ«åˆ°æ–‡æœ¬*")
    md_parts.append("")
    md_parts.append("## å›¾ç‰‡")
    md_parts.append("")
    # ç”±å¯¼å‡ºå‡½æ•°å†™å…¥ input_image.jpgï¼Œåœ¨æ­¤ä½¿ç”¨å›ºå®šç›¸å¯¹è·¯å¾„
    md_parts.append("![è¾“å…¥å›¾ç‰‡](input_image.jpg)")
    md_parts.append("")
    return "\n".join(md_parts)


def export_markdown(markdown_text: str, image_obj):
    """
    å°† Markdown ä¸å›¾ç‰‡å¯¼å‡ºåˆ°æœ¬åœ°ä¸´æ—¶ç›®å½•ï¼Œå¹¶è¿”å› .md æ–‡ä»¶è·¯å¾„ç”¨äºä¸‹è½½ã€‚
    - åœ¨ä¸´æ—¶ç›®å½•å†™å…¥ input_image.jpg å’Œ result.md
    - Gradio çš„ File ç»„ä»¶æ¥æ”¶ .md æ–‡ä»¶è·¯å¾„ä»¥ä¾›ä¸‹è½½
    """
    try:
        temp_dir = tempfile.mkdtemp()
        md_path = os.path.join(temp_dir, "result.md")
        img_path = os.path.join(temp_dir, "input_image.jpg")

        # ä¿å­˜å›¾ç‰‡
        if image_obj is not None:
            if isinstance(image_obj, str) and os.path.exists(image_obj):
                shutil.copy(image_obj, img_path)
            else:
                # å°è¯•ä½œä¸º PIL.Image ä¿å­˜
                try:
                    image_obj.save(img_path)
                except Exception:
                    # é PIL.Image ç±»å‹ï¼Œåˆ™ä¸ä¿å­˜å›¾ç‰‡
                    pass

        # å†™å…¥ Markdown
        with open(md_path, "w", encoding="utf-8") as f:
            f.write(markdown_text or "")

        return md_path
    except Exception as e:
        # è¿”å› None è®© File ä¸æ˜¾ç¤ºï¼ŒåŒæ—¶å¯åœ¨ UI ä¸Šæç¤º
        print(f"å¯¼å‡ºå¤±è´¥: {e}")
        return None


def create_demo():
    """Create Gradio interface"""

    with gr.Blocks(title="DeepSeek-OCR Demo", theme=gr.themes.Soft()) as demo:
        gr.Markdown(
            """
            # ğŸ” DeepSeek-OCR

            Upload an image containing text, documents, charts, or tables to extract text using DeepSeek-OCR.

            **Features:**
            - Free OCR for general text extraction
            - Markdown conversion for document structure
            - Multiple model sizes for different accuracy/speed tradeoffs
            - Support for various document types
            """
        )

        with gr.Row():
            with gr.Column(scale=1):
                # Input section
                gr.Markdown("### ğŸ“¤ Input")
                image_input = gr.Image(
                    label="Upload Image",
                    type="pil",
                    sources=["upload", "clipboard"]
                )

                gr.Markdown("### âš™ï¸ Settings")

                prompt_type = gr.Radio(
                    choices=["Free OCR", "Markdown Conversion", "Custom"],
                    value="Markdown Conversion",
                    label="Prompt Type",
                    info="Choose the type of OCR processing"
                )

                custom_prompt = gr.Textbox(
                    label="Custom Prompt (if selected)",
                    placeholder="Enter your custom prompt here...",
                    lines=2,
                    visible=False
                )

                model_size = gr.Radio(
                    choices=[
                        "Tiny",
                        "Small",
                        "Base",
                        "Large",
                        "Gundam (Recommended)"
                    ],
                    value="Gundam (Recommended)",
                    label="Model Size",
                    info="Larger models are more accurate but slower"
                )

                process_btn = gr.Button("ğŸš€ Process Image", variant="primary", size="lg")

                gr.Markdown(
                    """
                    ### ğŸ’¡ Tips
                    - **Gundam** mode works best for most documents
                    - Use **Markdown Conversion** for structured documents
                    - **Free OCR** for simple text extraction
                    - Higher resolution images give better results
                    """
                )

            with gr.Column(scale=1):
                # Output section
                gr.Markdown("### ğŸ“„ Results")
                output_text = gr.Textbox(
                    label="Extracted Text",
                    lines=20,
                    max_lines=30,
                    show_copy_button=True
                )

                # æ–°å¢ï¼šLaTeX è½¬æ–‡æœ¬ + Markdown ç”Ÿæˆ/å¯¼å‡º
                gr.Markdown("### ğŸ“ Markdown")
                readable_toggle = gr.Checkbox(
                    label="å°† LaTeX è½¬æ¢ä¸ºå¯è¯»æ–‡æœ¬ï¼ˆpylatexencï¼‰",
                    value=True,
                    info="å¼€å¯åå°†ä½¿ç”¨ pylatexenc æŠŠ LaTeX è½¬ä¸ºæ™®é€šæ–‡æœ¬"
                )
                generate_md_btn = gr.Button("ğŸ“ ç”Ÿæˆ Markdown", variant="secondary")
                md_preview = gr.Markdown(label="Markdown é¢„è§ˆ", value="")
                export_md_btn = gr.Button("ğŸ’¾ å¯¼å‡º Markdown", variant="secondary")
                md_file = gr.File(label="ä¸‹è½½ç”Ÿæˆçš„ Markdown æ–‡ä»¶", interactive=False)

                gr.Markdown(
                    """
                    ### ğŸ“¥ Export
                    1) ç‚¹å‡»â€œç”Ÿæˆ Markdownâ€é¢„è§ˆæ–‡æœ¬ä¸å›¾ç‰‡
                    2) ç‚¹å‡»â€œå¯¼å‡º Markdownâ€ä¿å­˜è‡³æœ¬åœ°ä¸´æ—¶ç›®å½•å¹¶ä¸‹è½½ .md æ–‡ä»¶ï¼ˆåŒ…å«å›¾ç‰‡ï¼‰
                    """
                )

        # Show/hide custom prompt based on selection
        def update_prompt_visibility(choice):
            return gr.update(visible=(choice == "Custom"))

        prompt_type.change(
            fn=update_prompt_visibility,
            inputs=[prompt_type],
            outputs=[custom_prompt]
        )

        # Process button click
        process_btn.click(
            fn=process_image,
            inputs=[image_input, prompt_type, custom_prompt, model_size],
            outputs=[output_text]
        )

        # ç”Ÿæˆ Markdown é€»è¾‘
        def to_readable_and_md(text_result, image_obj, use_readable):
            """
            å°†æ–‡æœ¬ï¼ˆå¯èƒ½ä¸º LaTeXï¼‰è½¬æ¢ä¸ºå¯è¯»æ–‡æœ¬ï¼Œå¹¶ç”Ÿæˆ Markdown é¢„è§ˆã€‚
            """
            try:
                readable = latex_to_readable_text(text_result) if use_readable else text_result
                md_str = build_markdown_with_image(readable, image_obj)
                return md_str
            except Exception as e:
                return f"ç”Ÿæˆ Markdown å¤±è´¥ï¼š{e}"

        generate_md_btn.click(
            fn=to_readable_and_md,
            inputs=[output_text, image_input, readable_toggle],
            outputs=[md_preview]
        )

        # å¯¼å‡º Markdown é€»è¾‘
        def on_export_md(md_str, image_obj):
            """
            å¯¼å‡º Markdown åˆ°ä¸´æ—¶ç›®å½•å¹¶è¿”å›ä¸‹è½½æ–‡ä»¶ã€‚
            """
            file_path = export_markdown(md_str, image_obj)
            return file_path

        export_md_btn.click(
            fn=on_export_md,
            inputs=[md_preview, image_input],
            outputs=[md_file]
        )

        # Add examples
        gr.Markdown("### ğŸ“š Example Images")
        gr.Examples(
            examples=[
                ["example_document.jpg", "Markdown Conversion", "", "Gundam (Recommended)"],
                ["example_receipt.jpg", "Free OCR", "", "Small"],
            ],
            inputs=[image_input, prompt_type, custom_prompt, model_size],
            outputs=[output_text],
            fn=process_image,
            cache_examples=False,
        )

        gr.Markdown(
            """
            ---
            ### â„¹ï¸ About

            This demo uses [DeepSeek-OCR](https://huggingface.co/deepseek-ai/DeepSeek-OCR) for optical character recognition.

            **Model Sizes Explained:**
            - **Tiny**: Fastest, lowest accuracy (512x512)
            - **Small**: Fast, good for simple documents (640x640)
            - **Base**: Balanced performance (1024x1024)
            - **Large**: High accuracy, slower (1280x1280)
            - **Gundam (Recommended)**: Balanced config with crop mode for complex docs
            """
        )

    return demo


if __name__ == "__main__":
    demo = create_demo()
    # å…è®¸æœ¬åœ°è®¿é—®ï¼Œå¯æŒ‰éœ€ä¿®æ”¹ server_name/port
    demo.launch(server_name="0.0.0.0", server_port=7860, share=False)
