# run_gradio.py
# ä¾èµ–: pip install gradio transformers torch pillow pylatexenc

import gradio as gr
from transformers import AutoModel, AutoTokenizer
import torch
import os
from PIL import Image
import tempfile
import shutil
import io
import base64
import re

# pylatexenc ç”¨äº LaTeX -> å¯è¯»æ–‡æœ¬
try:
    from pylatexenc.latex2text import LatexNodes2Text
except Exception:
    LatexNodes2Text = None
    print("è­¦å‘Š: pylatexenc æœªå®‰è£…ï¼ŒLaTeX è½¬æ–‡æœ¬å°†å›é€€åˆ°åŸæ–‡ã€‚å¯æ‰§è¡Œ: pip install pylatexenc")

# å…¨å±€æ¨¡å‹å˜é‡
model = None
tokenizer = None


def load_model():
    """å»¶è¿ŸåŠ è½½ DeepSeek-OCR æ¨¡å‹ä¸ tokenizer"""
    global model, tokenizer
    if model is None:
        print("Loading DeepSeek-OCR model...")
        model_name = 'deepseek-ai/DeepSeek-OCR'
        tokenizer = AutoTokenizer.from_pretrained(model_name, trust_remote_code=True)
        model = AutoModel.from_pretrained(
            model_name,
            _attn_implementation='flash_attention_2',
            trust_remote_code=True,
            use_safetensors=True
        )
        # å°è¯• GPU+bfloat16ï¼Œè‹¥å¤±è´¥å›é€€ CPU+float32
        try:
            model = model.eval().cuda().to(torch.bfloat16)
        except Exception:
            model = model.eval().to(torch.float32)
        print("Model loaded successfully!")
    return model, tokenizer


# -------------------------
# PIL -> base64 data URI è¾…åŠ©
# -------------------------
def pil_image_to_base64_datauri(img: Image.Image, max_width=1200, quality=85, fmt="JPEG"):
    """å°† PIL.Image è½¬ä¸º base64 data URIï¼ˆç¼©æ”¾ + å‹ç¼©ä»¥æ§åˆ¶å¤§å°ï¼‰"""
    if img is None:
        return None
    try:
        w, h = img.size
    except Exception:
        return None

    if max_width and w > max_width:
        new_w = max_width
        new_h = int(h * (new_w / w))
        img = img.resize((new_w, new_h), Image.LANCZOS)

    img_format = fmt.upper()
    buf = io.BytesIO()
    save_kwargs = {}
    if img_format == "JPEG":
        if img.mode in ("RGBA", "LA"):
            background = Image.new("RGB", img.size, (255, 255, 255))
            background.paste(img, mask=img.split()[3])
            img_to_save = background
        else:
            img_to_save = img.convert("RGB")
        save_kwargs["quality"] = quality
    else:
        img_to_save = img

    img_to_save.save(buf, format=img_format, **save_kwargs)
    b = buf.getvalue()
    encoded = base64.b64encode(b).decode("ascii")
    mime = "image/jpeg" if img_format == "JPEG" else f"image/{img_format.lower()}"
    return f"data:{mime};base64,{encoded}"


# -------------------------
# æ‰¾åˆ° temp_dir ä¸­çš„å›¾ç‰‡ï¼ˆæ•´å›¾ä¸ç¢å›¾ï¼‰
# -------------------------
def collect_images_from_output_dir(output_dir, max_patches=32):
    """
    åœ¨æ¨¡å‹è¾“å‡ºç›®å½•ä¸­æŸ¥æ‰¾å›¾ç‰‡æ–‡ä»¶ï¼Œåˆ†ä¸ºï¼š
      - overall_images: å¯èƒ½çš„å¯è§†åŒ–æ•´å›¾ï¼ˆé€‰ä¼˜å…ˆçº§é«˜çš„ï¼‰
      - patch_images: å¯èƒ½çš„ç¢å›¾ / crops / patches
    è¿”å›ï¼š (overall_images_list[PIL.Image], patch_images_list[PIL.Image])
    """
    overall_images = []
    patch_images = []

    if not output_dir or not os.path.exists(output_dir):
        return overall_images, patch_images

    exts = ('.png', '.jpg', '.jpeg', '.webp')
    keywords_patch = ['patch', 'patches', 'crop', 'crops', 'fragment', 'frag', 'cropbox', 'box', 'crop_img', 'patch_img']
    keywords_overall = ['result', 'vis', 'visual', 'output', 'pred', 'ocr', 'final']

    # æ”¶é›†æ‰€æœ‰å›¾ç‰‡è·¯å¾„
    image_paths = []
    for root, dirs, files in os.walk(output_dir):
        for f in files:
            if f.lower().endswith(exts):
                image_paths.append(os.path.join(root, f))

    # ä¼˜å…ˆæŒ‘é€‰å¸¦å…³é”®è¯çš„æ–‡ä»¶åˆ°å¯¹åº”åˆ—è¡¨
    for p in image_paths:
        name = os.path.basename(p).lower()
        if any(k in name for k in keywords_patch):
            patch_images.append(p)
        elif any(k in name for k in keywords_overall):
            overall_images.append(p)
        else:
            # æ— æ˜æ˜¾å…³é”®è¯ï¼Œæš‚å…ˆä½œä¸º patch å€™é€‰
            patch_images.append(p)

    # å»é‡å¹¶æŒ‰ä¼˜å…ˆçº§æ’åºï¼ˆæ•´ä½“å›¾æŒ‰ size æˆ–å…³é”®å­—å¾—åˆ†ï¼‰
    def score_overall(path):
        n = os.path.basename(path).lower()
        s = 0
        for i, kw in enumerate(keywords_overall):
            if kw in n:
                s += (len(keywords_overall) - i) * 10
        try:
            s += int(os.path.getsize(path) / 1024)
        except Exception:
            pass
        return s

    overall_images = sorted(set(overall_images), key=lambda x: score_overall(x), reverse=True)
    # patch_images ä¿æŒæ‰¾åˆ°é¡ºåºï¼Œä½†å»é‡
    patch_images = list(dict.fromkeys(patch_images))

    # è¯»å–ä¸º PIL.Image å¯¹è±¡ï¼ˆæ•´ä½“å›¾åªå–ç¬¬ä¸€å¼ ä½œä¸ºâ€œæ•´ä½“å¯è§†åŒ–å›¾â€ï¼‰
    overall_pils = []
    patch_pils = []

    for p in overall_images:
        try:
            overall_pils.append(Image.open(p).convert("RGB"))
        except Exception:
            continue

    for p in patch_images:
        try:
            patch_pils.append(Image.open(p).convert("RGB"))
        except Exception:
            continue
        if len(patch_pils) >= max_patches:
            break

    return overall_pils, patch_pils


# -------------------------
# LaTeX -> å¯è¯»æ–‡æœ¬
# -------------------------
def latex_to_readable_text(latex_str: str) -> str:
    if not latex_str or not latex_str.strip():
        return latex_str
    if LatexNodes2Text is None:
        return latex_str
    try:
        return LatexNodes2Text().latex_to_text(latex_str)
    except Exception:
        return latex_str


# -------------------------
# ä¸»æµç¨‹ï¼šè¿è¡Œæ¨¡å‹æ¨ç†å¹¶åœ¨ temp_dir ä¸­æ”¶é›†æ¨¡å‹ç”Ÿæˆçš„å›¾ç‰‡
# -------------------------
def process_image_and_collect_output_images(image, prompt_type, custom_prompt, model_size):
    """
    è¿è¡Œæ¨¡å‹æ¨ç†å¹¶è¿”å›ï¼š
      - readable_text: OCR æ–‡æœ¬ï¼ˆLaTeX å·²è½¬æ¢ä¸ºå¯è¯»æ–‡æœ¬ï¼‰
      - patch_images: list[PIL.Image]ï¼ˆæ¨¡å‹è¾“å‡ºç›®å½•ä¸­çš„ç¢å›¾ / cropsï¼‰
    """
    try:
        model, tokenizer = load_model()
        temp_dir = tempfile.mkdtemp()

        # ä¿å­˜ä¸Šä¼ å›¾åƒ
        temp_image_path = os.path.join(temp_dir, "input_image.jpg")
        if isinstance(image, str):
            shutil.copy(image, temp_image_path)
        else:
            image.save(temp_image_path)

        # æ„é€  prompt
        if prompt_type == "Free OCR":
            prompt = "<image>\nFree OCR. "
        elif prompt_type == "Markdown Conversion":
            prompt = "<image>\n<|grounding|>Convert the document to markdown. "
        elif prompt_type == "Custom":
            prompt = f"<image>\n{custom_prompt}"
        else:
            prompt = "<image>\nFree OCR. "

        size_configs = {
            "Tiny": {"base_size": 512, "image_size": 512, "crop_mode": False},
            "Small": {"base_size": 640, "image_size": 640, "crop_mode": False},
            "Base": {"base_size": 1024, "image_size": 1024, "crop_mode": False},
            "Large": {"base_size": 1280, "image_size": 1280, "crop_mode": False},
            "Gundam (Recommended)": {"base_size": 1024, "image_size": 640, "crop_mode": True}
        }
        config = size_configs.get(model_size, size_configs["Gundam (Recommended)"])

        # æ•è· stdout å¹¶è¿è¡Œ model.inferï¼ˆè®¸å¤šå®ç°ä¼šæŠŠç»“æœå†™å…¥ output_pathï¼‰
        import sys
        from io import StringIO
        old_stdout = sys.stdout
        sys.stdout = captured_output = StringIO()
        try:
            result = model.infer(
                tokenizer,
                prompt=prompt,
                image_file=temp_image_path,
                output_path=temp_dir,
                base_size=config["base_size"],
                image_size=config["image_size"],
                crop_mode=config["crop_mode"],
                save_results=True,
                test_compress=False
            )
        finally:
            sys.stdout = old_stdout

        captured_text = captured_output.getvalue()

        # å°è¯•è¯»å– temp_dir ä¸‹çš„æ–‡æœ¬æ–‡ä»¶ä½œä¸º OCR æ–‡æœ¬
        ocr_text = ""
        for filename in os.listdir(temp_dir):
            if filename.endswith('.txt'):
                try:
                    with open(os.path.join(temp_dir, filename), 'r', encoding='utf-8') as f:
                        ocr_text += f.read() + "\n"
                except Exception:
                    pass

        # è‹¥æ—  txtï¼Œåˆ™è§£æ captured_textï¼ˆå…¼å®¹è€å®ç°ï¼‰
        if not ocr_text.strip() and captured_text.strip():
            lines = captured_text.splitlines()
            clean_lines = []
            for line in lines:
                if '<|ref|>' in line or '<|det|>' in line or '<|/ref|>' in line or '<|/det|>' in line:
                    m = re.search(r'<\|/ref\|>(.*?)<\|det\|>', line)
                    if m:
                        clean_lines.append(m.group(1).strip())
                elif line.startswith('=====') or 'BASE:' in line or 'PATCHES:' in line or line.startswith('image:') or line.startswith('other:'):
                    continue
                elif line.strip():
                    clean_lines.append(line.strip())
            ocr_text = "\n".join(clean_lines)

        if not ocr_text.strip() and isinstance(result, str):
            ocr_text = result

        readable = latex_to_readable_text(ocr_text) if ocr_text else ""

        # åœ¨ temp_dir ä¸­æ”¶é›†æ¨¡å‹ç”Ÿæˆçš„å›¾ç‰‡ï¼ˆæ•´å›¾ä¸ç¢å›¾ï¼‰
        overall_imgs, patch_imgs = collect_images_from_output_dir(temp_dir, max_patches=48)

        # If model outputs only overall visualizations, but you want patches, you could
        # implement bbox parsing and cropping here (requires model output format).
        # For now: treat patch_imgs as "è¯†åˆ«ä¸ºå›¾ç‰‡çš„å†…å®¹" to be returned and embedded.

        # æ¸…ç†ä¸´æ—¶ç›®å½•ï¼ˆpatch_imgs å·²åŠ è½½åˆ°å†…å­˜ï¼‰
        try:
            shutil.rmtree(temp_dir)
        except Exception:
            pass

        return readable if readable.strip() else "No text detected in image.", patch_imgs

    except Exception as e:
        import traceback
        msg = f"Error: {str(e)}\n\nTraceback:\n{traceback.format_exc()}"
        return msg, []


# -------------------------
# å°† PIL åˆ—è¡¨è½¬æ¢ä¸º base64 åˆ—è¡¨
# -------------------------
def images_to_base64_list(images, max_width=600, quality=85, fmt="JPEG"):
    uris = []
    if not images:
        return uris
    for img in images:
        try:
            if isinstance(img, str) and os.path.exists(img):
                pil_img = Image.open(img).convert("RGB")
            else:
                pil_img = img
            uri = pil_image_to_base64_datauri(pil_img, max_width=max_width, quality=quality, fmt=fmt)
            if uri:
                uris.append(uri)
        except Exception:
            continue
    return uris


# -------------------------
# æ„å»º Markdownï¼šæŠŠæ‰€æœ‰ patch å›¾ä½œä¸ºâ€œè¯†åˆ«ä¸ºå›¾ç‰‡çš„å†…å®¹â€ä»¥ base64 åµŒå…¥
# -------------------------
def build_markdown_from_text_and_patches(readable_text: str, patches_images=None, patches_base64=None,
                                        embed_base64=True, patch_max_width=600, quality=85):
    if patches_base64 is None and patches_images:
        patches_base64 = images_to_base64_list(patches_images, max_width=patch_max_width, quality=quality)

    md = []
    md.append("# OCR ç»“æœ\n")
    md.append("## æ–‡æœ¬\n")
    md.append(readable_text or "*æœªè¯†åˆ«åˆ°æ–‡æœ¬*")
    md.append("\n---\n")
    md.append("## è¯†åˆ«ä¸ºå›¾ç‰‡çš„å†…å®¹ï¼ˆç¢å›¾ï¼‰\n")
    num = len(patches_base64) if patches_base64 else (len(patches_images) if patches_images else 0)
    md.append(f"_å…±è¯†åˆ«åˆ° {num} å¼ å›¾ç‰‡æ ·å¼çš„ç¢å›¾_\n\n")

    if num == 0:
        md.append("_æ— è¯†åˆ«å›¾ç‰‡_\n")
    else:
        for idx, uri in enumerate(patches_base64 or [], start=1):
            md.append(f"### å›¾ç‰‡ç‰‡æ®µ {idx}\n")
            md.append(f"![patch_{idx}]({uri})\n")
            md.append("\n")
    return "\n".join(md)


# -------------------------
# å¯¼å‡º Markdownï¼ˆå†™å…¥ä¸´æ—¶ç›®å½•å¹¶è¿”å› md è·¯å¾„ï¼‰
# -------------------------
def export_markdown_with_patches(markdown_text: str, patches_images, embed_base64=True, quality=85):
    try:
        temp_dir = tempfile.mkdtemp()
        md_path = os.path.join(temp_dir, "result.md")

        if not embed_base64:
            # ä¿å­˜ patches åˆ°ç›®å½•ï¼Œmd éœ€å¼•ç”¨ç›¸å¯¹è·¯å¾„ â€”â€” æ­¤å¤„é€šå¸¸æˆ‘ä»¬é»˜è®¤ embed=True
            for idx, p in enumerate(patches_images or [], start=1):
                try:
                    p.save(os.path.join(temp_dir, f"patch_{idx}.jpg"), quality=quality)
                except Exception:
                    pass

        with open(md_path, "w", encoding="utf-8") as f:
            f.write(markdown_text or "")

        return md_path
    except Exception as e:
        print(f"å¯¼å‡ºå¤±è´¥: {e}")
        return None


# -------------------------
# Gradio ç•Œé¢ï¼ˆç®€æ´å¸ƒå±€ï¼‰
# -------------------------
def create_demo():
    with gr.Blocks(title="DeepSeek-OCR (patches embedded)", theme=gr.themes.Soft()) as demo:
        gr.Markdown("# ğŸ” DeepSeek-OCR - æŠŠæ¨¡å‹ç”Ÿæˆçš„å°ç¢å›¾åµŒå…¥ Markdown\nä¸Šä¼ å›¾ç‰‡ -> OCR -> è¿”å›å¯è¯»æ–‡æœ¬ + è¯†åˆ«ä¸ºå›¾ç‰‡çš„ç¢å›¾ã€‚ç”Ÿæˆ Markdown æ—¶ä»¥ base64 åµŒå…¥è¿™äº›ç¢å›¾ã€‚")

        with gr.Row():
            with gr.Column(scale=1):
                gr.Markdown("### ğŸ“¤ Input & Settings")
                image_input = gr.Image(label="Upload Image", type="pil", sources=["upload", "clipboard"])
                prompt_type = gr.Radio(choices=["Free OCR", "Markdown Conversion", "Custom"], value="Markdown Conversion", label="Prompt Type")
                custom_prompt = gr.Textbox(label="Custom Prompt (if selected)", placeholder="Enter custom prompt...", lines=2, visible=False)
                model_size = gr.Radio(choices=["Tiny", "Small", "Base", "Large", "Gundam (Recommended)"], value="Gundam (Recommended)", label="Model Size")
                process_btn = gr.Button("ğŸš€ Process Image", variant="primary")

                def update_prompt_visibility(choice):
                    return gr.update(visible=(choice == "Custom"))
                prompt_type.change(fn=update_prompt_visibility, inputs=[prompt_type], outputs=[custom_prompt])

            with gr.Column(scale=1):
                gr.Markdown("### ğŸ“„ Results")
                output_text = gr.Textbox(label="Extracted Text (readable)", lines=18, max_lines=200, show_copy_button=True)
                patches_gallery = gr.Gallery(label="è¯†åˆ«ä¸ºå›¾ç‰‡çš„ç¢å›¾ (patches)", columns=6, type="pil")

                gr.Markdown("### ğŸ“ Markdown / Export")
                readable_toggle = gr.Checkbox(label="å°† LaTeX è½¬æ¢ä¸ºå¯è¯»æ–‡æœ¬ï¼ˆpylatexencï¼‰", value=True)
                embed_toggle = gr.Checkbox(label="åœ¨ Markdown ä¸­åµŒå…¥å›¾ç‰‡ï¼ˆBase64ï¼‰", value=True)
                generate_md_btn = gr.Button("ğŸ“ ç”Ÿæˆ Markdown")
                md_preview = gr.Markdown(label="Markdown é¢„è§ˆ", value="")
                export_md_btn = gr.Button("ğŸ’¾ å¯¼å‡º Markdown (.md)")
                md_file = gr.File(label="ä¸‹è½½ç”Ÿæˆçš„ Markdown æ–‡ä»¶", interactive=False)

        # å¤„ç† -> è¿”å›å¯è¯»æ–‡æœ¬, patches åˆ—è¡¨
        process_btn.click(
            fn=process_image_and_collect_output_images,
            inputs=[image_input, prompt_type, custom_prompt, model_size],
            outputs=[output_text, patches_gallery]
        )

        # ç”Ÿæˆ Markdownï¼ˆæŠŠ patches è½¬ä¸º base64 åµŒå…¥ï¼‰
        def to_md(text_result, patches_list, use_readable, embed_base64):
            readable = text_result or ""
            patches_images = patches_list or []
            md = build_markdown_from_text_and_patches(readable, patches_images=patches_images, patches_base64=None, embed_base64=embed_base64)
            return md

        generate_md_btn.click(
            fn=to_md,
            inputs=[output_text, patches_gallery, readable_toggle, embed_toggle],
            outputs=[md_preview]
        )

        # å¯¼å‡º Markdownï¼ˆè¿”å› md è·¯å¾„ï¼‰
        def export_md(md_str, patches_list, embed_base64):
            patches_images = patches_list or []
            md_path = export_markdown_with_patches(md_str, patches_images, embed_base64=embed_base64)
            return md_path

        export_md_btn.click(
            fn=export_md,
            inputs=[md_preview, patches_gallery, embed_toggle],
            outputs=[md_file]
        )

    return demo


if __name__ == "__main__":
    demo = create_demo()
    demo.launch(server_name="0.0.0.0", server_port=2714, share=False)
