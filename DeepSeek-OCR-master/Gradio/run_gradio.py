# run_gradio.py
# ä¾èµ–: pip install gradio transformers torch pillow pylatexenc

import gradio as gr
from transformers import AutoModel, AutoTokenizer
import torch
import os
from PIL import Image
import tempfile
import shutil
import io
import base64
import re

# pylatexenc ç”¨äº LaTeX -> å¯è¯»æ–‡æœ¬
try:
    from pylatexenc.latex2text import LatexNodes2Text
except Exception:
    LatexNodes2Text = None
    print("è­¦å‘Š: pylatexenc æœªå®‰è£…ï¼ŒLaTeX è½¬æ–‡æœ¬å°†å›é€€åˆ°åŸæ–‡ã€‚å¯æ‰§è¡Œ: pip install pylatexenc")

# å…¨å±€æ¨¡å‹å˜é‡
model = None
tokenizer = None


def load_model():
    """å»¶è¿ŸåŠ è½½ DeepSeek-OCR æ¨¡å‹ä¸ tokenizer"""
    global model, tokenizer
    if model is None:
        print("Loading DeepSeek-OCR model...")
        model_name = 'deepseek-ai/DeepSeek-OCR'
        tokenizer = AutoTokenizer.from_pretrained(model_name, trust_remote_code=True)
        model = AutoModel.from_pretrained(
            model_name,
            _attn_implementation='flash_attention_2',
            trust_remote_code=True,
            use_safetensors=True
        )
        # é»˜è®¤å°è¯• GPU + bfloat16ï¼›å¦‚éœ€æ”¹ä¸º CPUï¼Œè¯·ä¿®æ”¹ä¸‹é¢ä¸€è¡Œ
        try:
            model = model.eval().cuda().to(torch.bfloat16)
        except Exception:
            # å¦‚æœæ²¡æœ‰ GPUï¼Œåˆ™é€€å› CPU float32
            model = model.eval().to(torch.float32)
        print("Model loaded successfully!")
    return model, tokenizer


# -------------------------
# PIL -> base64 data URI è¾…åŠ©
# -------------------------
def pil_image_to_base64_datauri(img: Image.Image, max_width=800, quality=85, fmt="JPEG"):
    """å°† PIL.Image è½¬ä¸º base64 data URIï¼ˆå‹ç¼©/ç¼©æ”¾ä»¥æ§åˆ¶å¤§å°ï¼‰"""
    if img is None:
        return None
    try:
        w, h = img.size
    except Exception:
        return None

    if max_width and w > max_width:
        new_w = max_width
        new_h = int(h * (new_w / w))
        img = img.resize((new_w, new_h), Image.LANCZOS)

    img_format = fmt.upper()
    buf = io.BytesIO()
    save_kwargs = {}
    if img_format == "JPEG":
        if img.mode in ("RGBA", "LA"):
            background = Image.new("RGB", img.size, (255, 255, 255))
            background.paste(img, mask=img.split()[3])
            img_to_save = background
        else:
            img_to_save = img.convert("RGB")
        save_kwargs["quality"] = quality
    else:
        img_to_save = img

    img_to_save.save(buf, format=img_format, **save_kwargs)
    b = buf.getvalue()
    encoded = base64.b64encode(b).decode("ascii")
    mime = "image/jpeg" if img_format == "JPEG" else f"image/{img_format.lower()}"
    return f"data:{mime};base64,{encoded}"


# -------------------------
# æ”¶é›†æ¨¡å‹è¾“å‡ºä¸­çš„ç¢å›¾ï¼ˆpatchesï¼‰
# -------------------------
def collect_patch_images(output_dir, max_patches=24):
    """
    åœ¨æ¨¡å‹è¾“å‡ºç›®å½•ä¸­æ”¶é›†å¯èƒ½çš„ç¢å›¾ï¼ˆpatches / crops / fragmentsï¼‰ã€‚
    è¿”å› PIL.Image åˆ—è¡¨ï¼ˆconvert("RGB")ï¼‰ã€‚
    """
    if not output_dir or not os.path.exists(output_dir):
        return []

    exts = ('.png', '.jpg', '.jpeg', '.webp')
    keywords = ['patch', 'patches', 'crop', 'crops', 'fragment', 'frag', 'cropbox', 'box', 'crop_img', 'patch_img', 'vis']
    found_paths = []

    # ä¼˜å…ˆæ‰¾å¸¦å…³é”®è¯çš„æ–‡ä»¶æˆ–ç›®å½•
    for root, dirs, files in os.walk(output_dir):
        dir_name = os.path.basename(root).lower()
        dir_priority = any(k in dir_name for k in keywords)
        for f in files:
            if f.lower().endswith(exts):
                full = os.path.join(root, f)
                fname = f.lower()
                if dir_priority or any(k in fname for k in keywords):
                    found_paths.append(full)

    # å›é€€æŸ¥æ‰¾ä»»æ„å›¾ç‰‡
    if not found_paths:
        for root, dirs, files in os.walk(output_dir):
            for f in files:
                if f.lower().endswith(exts):
                    found_paths.append(os.path.join(root, f))

    # å»é‡å¹¶æŒ‰å‘ç°é¡ºåº
    unique_paths = list(dict.fromkeys(found_paths))

    images = []
    for p in unique_paths:
        try:
            img = Image.open(p).convert("RGB")
            images.append(img)
        except Exception:
            continue
        if len(images) >= max_patches:
            break

    return images


# -------------------------
# è§£ææ¨¡å‹è¾“å‡ºæ–‡æœ¬ -> OCR æ–‡æœ¬ï¼ˆå¹¶å°è¯• latex è½¬æ¢ï¼‰
# -------------------------
def latex_to_readable_text(latex_str: str) -> str:
    if not latex_str or not latex_str.strip():
        return latex_str
    if LatexNodes2Text is None:
        return latex_str
    try:
        return LatexNodes2Text().latex_to_text(latex_str)
    except Exception:
        return latex_str


# -------------------------
# ä¸»æµç¨‹ï¼šè¿è¡Œæ¨¡å‹æ¨ç†å¹¶è¿”å› (readable_text, patches_list)
# -------------------------
def process_image_collect_patches(image, prompt_type, custom_prompt, model_size):
    """
    è¿è¡Œæ¨¡å‹æ¨ç†å¹¶æ”¶é›†ä½œä¸ºâ€œå›¾ç‰‡â€çš„è¯†åˆ«ç»“æœï¼ˆpatchesï¼‰ã€‚
    è¿”å›ï¼š
      - readable_text: LaTeX è½¬æ¢åçš„å¯è¯»æ–‡æœ¬ï¼ˆç”¨äº Resultsï¼‰
      - patches: list[PIL.Image]ï¼ˆç”¨äº Gallery å’Œ Markdown åµŒå…¥ï¼‰
    """
    try:
        model, tokenizer = load_model()
        temp_dir = tempfile.mkdtemp()

        # ä¿å­˜ä¸Šä¼ å›¾åƒåˆ°ä¸´æ—¶ç›®å½•
        temp_image_path = os.path.join(temp_dir, "input_image.jpg")
        if isinstance(image, str):
            shutil.copy(image, temp_image_path)
        else:
            image.save(temp_image_path)

        # prompt æ„å»º
        if prompt_type == "Free OCR":
            prompt = "<image>\nFree OCR. "
        elif prompt_type == "Markdown Conversion":
            prompt = "<image>\n<|grounding|>Convert the document to markdown. "
        elif prompt_type == "Custom":
            prompt = f"<image>\n{custom_prompt}"
        else:
            prompt = "<image>\nFree OCR. "

        size_configs = {
            "Tiny": {"base_size": 512, "image_size": 512, "crop_mode": False},
            "Small": {"base_size": 640, "image_size": 640, "crop_mode": False},
            "Base": {"base_size": 1024, "image_size": 1024, "crop_mode": False},
            "Large": {"base_size": 1280, "image_size": 1280, "crop_mode": False},
            "Gundam (Recommended)": {"base_size": 1024, "image_size": 640, "crop_mode": True}
        }
        config = size_configs.get(model_size, size_configs["Gundam (Recommended)"])

        # æ•è· stdout å¹¶æ‰§è¡Œæ¨¡å‹æ¨ç†ï¼ˆæ¨¡å‹å¯èƒ½ä¼šå°†æ–‡æœ¬/patcheså†™å…¥ temp_dirï¼‰
        import sys
        from io import StringIO
        old_stdout = sys.stdout
        sys.stdout = captured_output = StringIO()
        try:
            result = model.infer(
                tokenizer,
                prompt=prompt,
                image_file=temp_image_path,
                output_path=temp_dir,
                base_size=config["base_size"],
                image_size=config["image_size"],
                crop_mode=config["crop_mode"],
                save_results=True,
                test_compress=False
            )
        finally:
            sys.stdout = old_stdout

        captured_text = captured_output.getvalue()

        # 1) ä¼˜å…ˆè¯»å– temp_dir ä¸­çš„æ–‡æœ¬æ–‡ä»¶
        ocr_text = ""
        for filename in os.listdir(temp_dir):
            if filename.endswith('.txt'):
                try:
                    with open(os.path.join(temp_dir, filename), 'r', encoding='utf-8') as f:
                        ocr_text += f.read() + "\n"
                except Exception:
                    pass

        # 2) å¦‚æœæ²¡æœ‰ txtï¼Œåˆ™ä» captured_text è§£æ
        if not ocr_text.strip() and captured_text.strip():
            lines = captured_text.splitlines()
            clean_lines = []
            for line in lines:
                if '<|ref|>' in line or '<|det|>' in line or '<|/ref|>' in line or '<|/det|>' in line:
                    m = re.search(r'<\|/ref\|>(.*?)<\|det\|>', line)
                    if m:
                        clean_lines.append(m.group(1).strip())
                elif line.startswith('=====') or 'BASE:' in line or 'PATCHES:' in line or line.startswith('image:') or line.startswith('other:'):
                    continue
                elif line.strip():
                    clean_lines.append(line.strip())
            ocr_text = "\n".join(clean_lines)

        # 3) fallback å¦‚æœ result æ˜¯å­—ç¬¦ä¸²
        if not ocr_text.strip():
            if isinstance(result, str):
                ocr_text = result
            else:
                ocr_text = ""

        # è½¬æ¢ LaTeX åˆ°å¯è¯»æ–‡æœ¬ï¼ˆå¦‚æœå¯ç”¨ï¼‰
        readable = latex_to_readable_text(ocr_text) if ocr_text else ""

        # æ”¶é›† patchesï¼ˆæ¨¡å‹è¾“å‡ºç›®å½•ä¸­çš„å°å›¾ç‰‡ï¼‰
        patches = collect_patch_images(temp_dir, max_patches=32)

        # å¦‚æœæ¨¡å‹æ²¡æœ‰è¾“å‡ºç¢å›¾ï¼Œä½† OCR æ–‡æœ¬ä¸­å¯èƒ½åŒ…å« bbox ä¿¡æ¯ï¼Œå¯ä»¥åœ¨æ­¤è§£æå¹¶è£å‰ªåŸå›¾ç”Ÿæˆ patches
        # ï¼ˆå¦‚éœ€è§£æ bbox å¹¶è£å‰ªï¼Œè¯·æä¾› captured_text çš„ç¤ºä¾‹æ ¼å¼ï¼Œæˆ‘å¯ä»¥å¸®ä½ æ·»åŠ è£å‰ªé€»è¾‘ï¼‰

        # æ¸…ç†ä¸´æ—¶ç›®å½•ï¼ˆpatches å·²åŠ è½½åˆ°å†…å­˜ï¼‰
        try:
            shutil.rmtree(temp_dir)
        except Exception:
            pass

        return readable if readable.strip() else "No text detected in image.", patches

    except Exception as e:
        import traceback
        msg = f"Error: {str(e)}\n\nTraceback:\n{traceback.format_exc()}"
        return msg, []


# -------------------------
# å°† patches åˆ—è¡¨è½¬æ¢ä¸º base64 åˆ—è¡¨
# -------------------------
def images_to_base64_list(images, max_width=600, quality=85, fmt="JPEG"):
    uris = []
    if not images:
        return uris
    for img in images:
        try:
            if isinstance(img, str) and os.path.exists(img):
                pil_img = Image.open(img).convert("RGB")
            else:
                pil_img = img
            uri = pil_image_to_base64_datauri(pil_img, max_width=max_width, quality=quality, fmt=fmt)
            if uri:
                uris.append(uri)
        except Exception:
            continue
    return uris


# -------------------------
# æ„å»º Markdownï¼ˆæŠŠ patches åµŒå…¥ä¸º base64 å¹¶æŒ‰æ ·å¼ç»„ç»‡ï¼‰
# -------------------------
def build_markdown_from_text_and_patches(readable_text: str, patches_images=None, patches_base64=None,
                                        embed_base64=True, max_width=1200, patch_max_width=600, quality=85):
    """
    readable_text: OCR å¯è¯»æ–‡æœ¬
    patches_images: list[PIL.Image]
    patches_base64: list[data uri strings]
    embed_base64: æ˜¯å¦åœ¨ md ä¸­åµŒå…¥ base64ï¼ˆTrue æ¨èï¼‰
    è¿”å› markdown å­—ç¬¦ä¸²
    """
    if patches_base64 is None and patches_images:
        patches_base64 = images_to_base64_list(patches_images, max_width=patch_max_width, quality=quality)

    md = []
    md.append("# OCR ç»“æœ\n")
    md.append("## æ–‡æœ¬\n")
    md.append(readable_text or "*æœªè¯†åˆ«åˆ°æ–‡æœ¬*")
    md.append("\n---\n")
    md.append("## è¯†åˆ«ä¸ºå›¾ç‰‡çš„å†…å®¹ï¼ˆç¢å›¾ï¼‰\n")
    num = len(patches_base64) if patches_base64 else (len(patches_images) if patches_images else 0)
    md.append(f"_å…±è¯†åˆ«åˆ° {num} å¼ å›¾ç‰‡æ ·å¼çš„ç¢å›¾_\n\n")

    if num == 0:
        md.append("_æ— è¯†åˆ«å›¾ç‰‡_\n")
    else:
        for idx, uri in enumerate(patches_base64 or [], start=1):
            md.append(f"### å›¾ç‰‡ç‰‡æ®µ {idx}\n")
            md.append(f"![patch_{idx}]({uri})\n")
            md.append("\n")
    return "\n".join(md)


# -------------------------
# å¯¼å‡º Markdownï¼ˆåµŒå…¥æˆ–ä¸åµŒå…¥ï¼‰
# -------------------------
def export_markdown_with_patches(markdown_text: str, patches_images, embed_base64=True, quality=85):
    """
    å°† markdown å†™åˆ°ä¸´æ—¶ç›®å½•å¹¶è¿”å›æ–‡ä»¶è·¯å¾„ç”¨äº gr.File ä¸‹è½½ã€‚
    å¦‚æœ embed_base64=Falseï¼Œä¼šæŠŠ patches_images å•ç‹¬ä¿å­˜åˆ°ç›®å½•å¹¶åœ¨ md ä¸­ä½¿ç”¨ç›¸å¯¹è·¯å¾„ï¼ˆä½†è¿™é‡Œæˆ‘ä»¬é»˜è®¤ embed=Trueï¼‰
    """
    try:
        temp_dir = tempfile.mkdtemp()
        md_path = os.path.join(temp_dir, "result.md")

        if not embed_base64:
            # å¦‚æœä¸åµŒå…¥ï¼Œåˆ™éœ€è¦ä¿å­˜ patches å¹¶æ›¿æ¢ md ä¸­çš„å¼•ç”¨ â€” å½“å‰å®ç°ä»¥ embed=True ä¸ºä¸»ï¼Œç”¨ä¸åˆ°æ­¤è·¯å¾„
            for idx, p in enumerate(patches_images or [], start=1):
                try:
                    p.save(os.path.join(temp_dir, f"patch_{idx}.jpg"), quality=quality)
                except Exception:
                    pass

        with open(md_path, "w", encoding="utf-8") as f:
            f.write(markdown_text or "")

        return md_path
    except Exception as e:
        print(f"å¯¼å‡ºå¤±è´¥: {e}")
        return None


# -------------------------
# Gradio ç•Œé¢ï¼ˆå·¦ä¾§è¾“å…¥ï¼Œå³ä¾§ç»“æœï¼‰
# -------------------------
def create_demo():
    with gr.Blocks(title="DeepSeek-OCR (patches as images)", theme=gr.themes.Soft()) as demo:
        gr.Markdown("# ğŸ” DeepSeek-OCR - å°†è¯†åˆ«ä¸ºå›¾ç‰‡çš„å†…å®¹åµŒå…¥ Markdown\nä¸Šä¼ å›¾ç‰‡ -> OCR -> è¿”å›å¯è¯»æ–‡æœ¬ä¸è¯†åˆ«ä¸ºå›¾ç‰‡çš„ç¢å›¾ï¼ˆpatchesï¼‰ã€‚ç”Ÿæˆ Markdown æ—¶ä»¥ base64 åµŒå…¥è¿™äº›ç¢å›¾ã€‚")

        with gr.Row():
            with gr.Column(scale=1):
                gr.Markdown("### ğŸ“¤ Input & Settings")
                image_input = gr.Image(label="Upload Image", type="pil", sources=["upload", "clipboard"])
                prompt_type = gr.Radio(choices=["Free OCR", "Markdown Conversion", "Custom"], value="Markdown Conversion", label="Prompt Type")
                custom_prompt = gr.Textbox(label="Custom Prompt (if selected)", placeholder="Enter custom prompt...", lines=2, visible=False)
                model_size = gr.Radio(choices=["Tiny", "Small", "Base", "Large", "Gundam (Recommended)"], value="Gundam (Recommended)", label="Model Size")
                process_btn = gr.Button("ğŸš€ Process Image", variant="primary")

                def update_prompt_visibility(choice):
                    return gr.update(visible=(choice == "Custom"))
                prompt_type.change(fn=update_prompt_visibility, inputs=[prompt_type], outputs=[custom_prompt])

            with gr.Column(scale=1):
                gr.Markdown("### ğŸ“„ Results")
                output_text = gr.Textbox(label="Extracted Text (readable)", lines=18, max_lines=200, show_copy_button=True)
                patches_gallery = gr.Gallery(label="è¯†åˆ«ä¸ºå›¾ç‰‡çš„ç¢å›¾ (patches)", columns=6, type="pil")

                gr.Markdown("### ğŸ“ Markdown / Export")
                readable_toggle = gr.Checkbox(label="å°† LaTeX è½¬æ¢ä¸ºå¯è¯»æ–‡æœ¬ï¼ˆpylatexencï¼‰", value=True)
                embed_toggle = gr.Checkbox(label="åœ¨ Markdown ä¸­åµŒå…¥å›¾ç‰‡ï¼ˆBase64ï¼‰", value=True)
                generate_md_btn = gr.Button("ğŸ“ ç”Ÿæˆ Markdown")
                md_preview = gr.Markdown(label="Markdown é¢„è§ˆ", value="")
                export_md_btn = gr.Button("ğŸ’¾ å¯¼å‡º Markdown (.md)")
                md_file = gr.File(label="ä¸‹è½½ç”Ÿæˆçš„ Markdown æ–‡ä»¶", interactive=False)

        # Process: å¾—åˆ°å¯è¯»æ–‡æœ¬ä¸ patches
        process_btn.click(
            fn=process_image_collect_patches,
            inputs=[image_input, prompt_type, custom_prompt, model_size],
            outputs=[output_text, patches_gallery]
        )

        # ç”Ÿæˆ Markdown
        def to_md(text_result, patches_list, use_readable, embed_base64):
            # text_result åœ¨ process å·²ç»ä¸ºå¯è¯»æ–‡æœ¬ï¼ˆå¦‚æœ process åšäº† latex è½¬æ¢ï¼‰
            readable = text_result or ""
            patches_images = patches_list or []
            md = build_markdown_from_text_and_patches(readable, patches_images=patches_images, patches_base64=None, embed_base64=embed_base64)
            return md

        generate_md_btn.click(
            fn=to_md,
            inputs=[output_text, patches_gallery, readable_toggle, embed_toggle],
            outputs=[md_preview]
        )

        # å¯¼å‡º Markdownï¼ˆè¿”å› md æ–‡ä»¶è·¯å¾„ï¼‰
        def export_md(md_str, patches_list, embed_base64):
            patches_images = patches_list or []
            md_path = export_markdown_with_patches(md_str, patches_images, embed_base64=embed_base64)
            return md_path

        export_md_btn.click(
            fn=export_md,
            inputs=[md_preview, patches_gallery, embed_toggle],
            outputs=[md_file]
        )

    return demo


if __name__ == "__main__":
    demo = create_demo()
    demo.launch(server_name="0.0.0.0", server_port=2714, share=False)
