# run_gradio.py
# ç¡®ä¿å®‰è£…äº† gradioï¼Œç”¨ pip install gradio
# ç¡®ä¿å®‰è£… pylatexenc ç”¨äº LaTeX è½¬æ–‡æœ¬ï¼špip install pylatexenc

import gradio as gr
from transformers import AutoModel, AutoTokenizer
import torch
import os
from PIL import Image
import tempfile
import shutil
import io
import base64

# pylatexenc ç”¨äº LaTeX è½¬æ–‡æœ¬
try:
    from pylatexenc.latex2text import LatexNodes2Text
except Exception as _e:
    print("pylatexenc æœªå®‰è£…ï¼Œè¯·å…ˆæ‰§è¡Œ: pip install pylatexenc")

# Global variables for model and tokenizer
model = None
tokenizer = None


def load_model():
    """Load the DeepSeek-OCR model and tokenizer"""
    global model, tokenizer

    if model is None:
        print("Loading DeepSeek-OCR model...")
        model_name = 'deepseek-ai/DeepSeek-OCR'

        tokenizer = AutoTokenizer.from_pretrained(model_name, trust_remote_code=True)
        model = AutoModel.from_pretrained(
            model_name,
            _attn_implementation='flash_attention_2',
            trust_remote_code=True,
            use_safetensors=True
        )
        model = model.eval().cuda().to(torch.bfloat16)
        print("Model loaded successfully!")

    return model, tokenizer


def process_image(image, prompt_type, custom_prompt, model_size):
    """Process image with OCR"""
    try:
        # Load model if not already loaded
        model, tokenizer = load_model()

        # Create temporary directory for output
        temp_dir = tempfile.mkdtemp()

        # Save uploaded image temporarily
        temp_image_path = os.path.join(temp_dir, "input_image.jpg")
        if isinstance(image, str):
            shutil.copy(image, temp_image_path)
        else:
            image.save(temp_image_path)

        # Set prompt based on selection
        if prompt_type == "Free OCR":
            prompt = "<image>\nFree OCR. "
        elif prompt_type == "Markdown Conversion":
            prompt = "<image>\n<|grounding|>Convert the document to markdown. "
        elif prompt_type == "Custom":
            prompt = f"<image>\n{custom_prompt}"
        else:
            prompt = "<image>\nFree OCR. "

        # Set model size parameters
        size_configs = {
            "Tiny": {"base_size": 512, "image_size": 512, "crop_mode": False},
            "Small": {"base_size": 640, "image_size": 640, "crop_mode": False},
            "Base": {"base_size": 1024, "image_size": 1024, "crop_mode": False},
            "Large": {"base_size": 1280, "image_size": 1280, "crop_mode": False},
            "Gundam (Recommended)": {"base_size": 1024, "image_size": 640, "crop_mode": True}
        }

        config = size_configs[model_size]

        # Capture stdout to get the OCR results
        import sys
        from io import StringIO

        # Redirect stdout to capture print statements
        old_stdout = sys.stdout
        sys.stdout = captured_output = StringIO()

        try:
            # Run inference
            result = model.infer(
                tokenizer,
                prompt=prompt,
                image_file=temp_image_path,
                output_path=temp_dir,
                base_size=config["base_size"],
                image_size=config["image_size"],
                crop_mode=config["crop_mode"],
                save_results=True,
                test_compress=False
            )
        finally:
            # Restore stdout
            sys.stdout = old_stdout

        # Get captured output
        captured_text = captured_output.getvalue()

        # Try to read from saved text file if it exists
        ocr_text = ""
        for filename in os.listdir(temp_dir):
            if filename.endswith('.txt'):
                with open(os.path.join(temp_dir, filename), 'r', encoding='utf-8') as f:
                    ocr_text += f.read() + "\n"

        # If we found text in files, use that; otherwise use captured output
        if ocr_text.strip():
            final_result = ocr_text.strip()
        elif captured_text.strip():
            # Parse the captured output to extract actual OCR text
            # Remove detection boxes and reference tags
            lines = captured_text.split('\n')
            clean_lines = []
            for line in lines:
                # Skip lines with detection boxes and reference tags
                if '<|ref|>' in line or '<|det|>' in line or '<|/ref|>' in line or '<|/det|>' in line:
                    # Extract text between tags
                    import re
                    # Pattern to match text between </ref|> and <|det|>
                    text_match = re.search(r'<\|/ref\|>(.*?)<\|det\|>', line)
                    if text_match:
                        clean_lines.append(text_match.group(1).strip())
                elif line.startswith('=====') or 'BASE:' in line or 'PATCHES:' in line or line.startswith(
                        'image:') or line.startswith('other:'):
                    continue
                elif line.strip():
                    clean_lines.append(line.strip())

            final_result = '\n'.join(clean_lines)
        elif isinstance(result, str):
            final_result = result
        else:
            final_result = str(result) if result else "No text detected in image."

        # Clean up temporary directory
        shutil.rmtree(temp_dir)

        return final_result if final_result.strip() else "No text detected in image."

    except Exception as e:
        import traceback
        return f"Error: {str(e)}\n\nTraceback:\n{traceback.format_exc()}\n\nPlease make sure you have a CUDA-enabled GPU and all dependencies installed."


# =========================
# æ–°å¢ï¼šLaTeX è½¬æ–‡æœ¬ä¸ Markdown æ„å»º/å¯¼å‡ºå·¥å…·å‡½æ•°ï¼ˆå« base64 åµŒå…¥ï¼‰
# =========================

def latex_to_readable_text(latex_str: str) -> str:
    """
    ä½¿ç”¨ pylatexenc å°† LaTeX è½¬æ¢ä¸ºå¯è¯»çº¯æ–‡æœ¬ã€‚
    å¦‚æœ pylatexenc ä¸å¯ç”¨æˆ–è½¬æ¢å¤±è´¥ï¼Œè¿”å›åŸæ–‡ã€‚
    """
    if not latex_str or not latex_str.strip():
        return latex_str
    try:
        return LatexNodes2Text().latex_to_text(latex_str)
    except Exception:
        return latex_str


def pil_image_to_base64_datauri(img: Image.Image, max_width=1200, quality=85, fmt="JPEG"):
    """
    å°† PIL Image è½¬ä¸º base64 data URIï¼ˆé»˜è®¤ JPEGï¼‰ã€‚
    - max_width: è‹¥å›¾ç‰‡å®½åº¦å¤§äºè¯¥å€¼ï¼Œå°†æŒ‰æ¯”ä¾‹ç¼©æ”¾
    - quality: JPEG å‹ç¼©è´¨é‡ï¼ˆ0-100ï¼‰
    è¿”å› data uri å­—ç¬¦ä¸²ï¼Œä¾‹å¦‚ "data:image/jpeg;base64,...."
    """
    if img is None:
        return None
    # ç¡®ä¿ä¸º PIL.Image
    try:
        w, h = img.size
    except Exception:
        return None

    # ç¼©æ”¾ï¼ˆä»…å®½åº¦ï¼‰
    if max_width and w > max_width:
        new_w = max_width
        new_h = int(h * (new_w / w))
        img = img.resize((new_w, new_h), Image.LANCZOS)

    img_format = fmt.upper()
    buf = io.BytesIO()
    # å¯¹ PNG æˆ–é€æ˜å›¾ç‰‡ï¼Œè‹¥éœ€è¦ä¿ç•™é€æ˜åº¦å¯ä½¿ç”¨ PNG
    save_kwargs = {}
    if img_format == "JPEG":
        # convert to RGB to avoid ä¿å­˜ RGBA å¯¼è‡´é”™è¯¯
        if img.mode in ("RGBA", "LA"):
            background = Image.new("RGB", img.size, (255, 255, 255))
            background.paste(img, mask=img.split()[3])  # 3 is alpha
            img_to_save = background
        else:
            img_to_save = img.convert("RGB")
        save_kwargs["quality"] = quality
    else:
        img_to_save = img

    img_to_save.save(buf, format=img_format, **save_kwargs)
    b = buf.getvalue()
    encoded = base64.b64encode(b).decode("ascii")
    mime = "image/jpeg" if img_format == "JPEG" else f"image/{img_format.lower()}"
    return f"data:{mime};base64,{encoded}"


def build_markdown_with_image(readable_text: str, image_obj, embed_base64=True, max_width=1200, quality=85):
    """
    ç”ŸæˆåŒ…å«æ–‡æœ¬ä¸å›¾ç‰‡çš„ Markdownã€‚
    - å¦‚æœ embed_base64=Trueï¼Œä¼šå°†è¾“å…¥å›¾ç‰‡ç¼–ç ä¸º base64 data URI å¹¶ç›´æ¥åµŒå…¥ Markdownã€‚
    - å¦åˆ™ä½¿ç”¨ç›¸å¯¹è·¯å¾„ 'input_image.jpg'ï¼ˆéœ€é…åˆå¯¼å‡ºæ—¶æ‰“åŒ…å›¾ç‰‡ï¼‰ã€‚
    """
    md_parts = []
    md_parts.append("# OCR ç»“æœ")
    md_parts.append("")
    md_parts.append("## æ–‡æœ¬")
    md_parts.append("")
    md_parts.append(readable_text if readable_text else "*æœªè¯†åˆ«åˆ°æ–‡æœ¬*")
    md_parts.append("")
    md_parts.append("## å›¾ç‰‡")
    md_parts.append("")

    if image_obj is None:
        md_parts.append("_æ— ä¸Šä¼ å›¾ç‰‡_")
    else:
        if embed_base64:
            # å¦‚æœ image_obj æ˜¯è·¯å¾„åˆ™å…ˆæ‰“å¼€
            try:
                if isinstance(image_obj, str) and os.path.exists(image_obj):
                    pil_img = Image.open(image_obj)
                else:
                    pil_img = image_obj  # æœŸæœ›æ˜¯ PIL.Image
                data_uri = pil_image_to_base64_datauri(pil_img, max_width=max_width, quality=quality)
                if data_uri:
                    md_parts.append(f"![è¾“å…¥å›¾ç‰‡]({data_uri})")
                else:
                    md_parts.append("![è¾“å…¥å›¾ç‰‡](input_image.jpg)")
            except Exception:
                md_parts.append("![è¾“å…¥å›¾ç‰‡](input_image.jpg)")
        else:
            md_parts.append("![è¾“å…¥å›¾ç‰‡](input_image.jpg)")

    md_parts.append("")
    return "\n".join(md_parts)


def export_markdown(markdown_text: str, image_obj, embed_base64=True, max_width=1200, quality=85):
    """
    å°† Markdown ä¸å›¾ç‰‡å¯¼å‡ºåˆ°æœ¬åœ°ä¸´æ—¶ç›®å½•ï¼Œå¹¶è¿”å› .md æ–‡ä»¶è·¯å¾„ç”¨äºä¸‹è½½ã€‚
    - å½“ embed_base64=True æ—¶ï¼ŒMarkdown ä¸­å·²åµŒå…¥å›¾ç‰‡ï¼Œæ— éœ€å•ç‹¬ä¿å­˜å›¾ç‰‡ï¼ˆ.md å³åŒ…å«å›¾åƒï¼‰
    - å½“ embed_base64=False æ—¶ï¼Œä¼šæŠŠå›¾ç‰‡ä¿å­˜ä¸º input_image.jpg ä¸ result.md åŒç›®å½•
    æ³¨æ„ï¼šå°† base64 åµŒå…¥ .md ä¼šä½¿æ–‡ä»¶æ›´å¤§ï¼Œä½†èƒ½ä¿è¯ Gradio å‰ç«¯é¢„è§ˆæ­£å¸¸ã€‚
    """
    try:
        temp_dir = tempfile.mkdtemp()
        md_path = os.path.join(temp_dir, "result.md")

        # å¦‚æœä¸åµŒå…¥ï¼Œéœ€è¦æŠŠå›¾ç‰‡å­˜ä¸º input_image.jpg
        if not embed_base64 and image_obj is not None:
            img_path = os.path.join(temp_dir, "input_image.jpg")
            try:
                if isinstance(image_obj, str) and os.path.exists(image_obj):
                    shutil.copy(image_obj, img_path)
                else:
                    image_obj.save(img_path)
            except Exception as e:
                print(f"ä¿å­˜å›¾ç‰‡å¤±è´¥: {e}")

        # å†™å…¥ Markdown
        with open(md_path, "w", encoding="utf-8") as f:
            f.write(markdown_text or "")

        return md_path
    except Exception as e:
        print(f"å¯¼å‡ºå¤±è´¥: {e}")
        return None


def create_demo():
    """Create Gradio interface"""

    with gr.Blocks(title="DeepSeek-OCR Demo", theme=gr.themes.Soft()) as demo:
        gr.Markdown(
            """
            # ğŸ” DeepSeek-OCR

            Upload an image containing text, documents, charts, or tables to extract text using DeepSeek-OCR.

            **Features:**
            - Free OCR for general text extraction
            - Markdown conversion for document structure
            - Multiple model sizes for different accuracy/speed tradeoffs
            - Support for various document types
            """
        )

        with gr.Row():
            with gr.Column(scale=1):
                # Input section
                gr.Markdown("### ğŸ“¤ Input")
                image_input = gr.Image(
                    label="Upload Image",
                    type="pil",
                    sources=["upload", "clipboard"]
                )

                gr.Markdown("### âš™ï¸ Settings")

                prompt_type = gr.Radio(
                    choices=["Free OCR", "Markdown Conversion", "Custom"],
                    value="Markdown Conversion",
                    label="Prompt Type",
                    info="Choose the type of OCR processing"
                )

                custom_prompt = gr.Textbox(
                    label="Custom Prompt (if selected)",
                    placeholder="Enter your custom prompt here...",
                    lines=2,
                    visible=False
                )

                model_size = gr.Radio(
                    choices=[
                        "Tiny",
                        "Small",
                        "Base",
                        "Large",
                        "Gundam (Recommended)"
                    ],
                    value="Gundam (Recommended)",
                    label="Model Size",
                    info="Larger models are more accurate but slower"
                )

                process_btn = gr.Button("ğŸš€ Process Image", variant="primary", size="lg")

                gr.Markdown(
                    """
                    ### ğŸ’¡ Tips
                    - **Gundam** mode works best for most documents
                    - Use **Markdown Conversion** for structured documents
                    - **Free OCR** for simple text extraction
                    - Higher resolution images give better results
                    """
                )

            with gr.Column(scale=1):
                # Output section
                gr.Markdown("### ğŸ“„ Results")
                output_text = gr.Textbox(
                    label="Extracted Text",
                    lines=20,
                    max_lines=30,
                    show_copy_button=True
                )

                # æ–°å¢ï¼šLaTeX è½¬æ–‡æœ¬ + Markdown ç”Ÿæˆ/å¯¼å‡º
                gr.Markdown("### ğŸ“ Markdown")
                readable_toggle = gr.Checkbox(
                    label="å°† LaTeX è½¬æ¢ä¸ºå¯è¯»æ–‡æœ¬ï¼ˆpylatexencï¼‰",
                    value=True,
                    info="å¼€å¯åå°†ä½¿ç”¨ pylatexenc æŠŠ LaTeX è½¬ä¸ºæ™®é€šæ–‡æœ¬"
                )
                embed_toggle = gr.Checkbox(
                    label="åœ¨ Markdown ä¸­åµŒå…¥å›¾ç‰‡ï¼ˆBase64ï¼‰",
                    value=True,
                    info="å¼€å¯åå›¾ç‰‡ä¼šä»¥ base64 data URI åµŒå…¥ Markdownï¼Œå‰ç«¯å¯ä»¥ç›´æ¥é¢„è§ˆ"
                )
                generate_md_btn = gr.Button("ğŸ“ ç”Ÿæˆ Markdown", variant="secondary")
                md_preview = gr.Markdown(label="Markdown é¢„è§ˆ", value="")
                export_md_btn = gr.Button("ğŸ’¾ å¯¼å‡º Markdown", variant="secondary")
                md_file = gr.File(label="ä¸‹è½½ç”Ÿæˆçš„ Markdown æ–‡ä»¶", interactive=False)

                gr.Markdown(
                    """
                    ### ğŸ“¥ Export
                    1) ç‚¹å‡»â€œç”Ÿæˆ Markdownâ€é¢„è§ˆæ–‡æœ¬ä¸å›¾ç‰‡
                    2) ç‚¹å‡»â€œå¯¼å‡º Markdownâ€ä¿å­˜è‡³æœ¬åœ°ä¸´æ—¶ç›®å½•å¹¶ä¸‹è½½ .md æ–‡ä»¶ï¼ˆåŒ…å«å›¾ç‰‡æˆ–ä¸å›¾ç‰‡é…å¥—ï¼‰
                    """
                )

        # Show/hide custom prompt based on selection
        def update_prompt_visibility(choice):
            return gr.update(visible=(choice == "Custom"))

        prompt_type.change(
            fn=update_prompt_visibility,
            inputs=[prompt_type],
            outputs=[custom_prompt]
        )

        # Process button click
        process_btn.click(
            fn=process_image,
            inputs=[image_input, prompt_type, custom_prompt, model_size],
            outputs=[output_text]
        )

        # ç”Ÿæˆ Markdown é€»è¾‘
        def to_readable_and_md(text_result, image_obj, use_readable, embed_base64):
            """
            å°†æ–‡æœ¬ï¼ˆå¯èƒ½ä¸º LaTeXï¼‰è½¬æ¢ä¸ºå¯è¯»æ–‡æœ¬ï¼Œå¹¶ç”Ÿæˆ Markdown é¢„è§ˆï¼ˆé»˜è®¤åµŒå…¥ base64ï¼‰ã€‚
            """
            try:
                readable = latex_to_readable_text(text_result) if use_readable else text_result
                md_str = build_markdown_with_image(readable, image_obj, embed_base64=embed_base64)
                return md_str
            except Exception as e:
                return f"ç”Ÿæˆ Markdown å¤±è´¥ï¼š{e}"

        generate_md_btn.click(
            fn=to_readable_and_md,
            inputs=[output_text, image_input, readable_toggle, embed_toggle],
            outputs=[md_preview]
        )

        # å¯¼å‡º Markdown é€»è¾‘
        def on_export_md(md_str, image_obj, embed_base64):
            """
            å¯¼å‡º Markdown åˆ°ä¸´æ—¶ç›®å½•å¹¶è¿”å›ä¸‹è½½æ–‡ä»¶ã€‚
            """
            file_path = export_markdown(md_str, image_obj, embed_base64=embed_base64)
            return file_path

        export_md_btn.click(
            fn=on_export_md,
            inputs=[md_preview, image_input, embed_toggle],
            outputs=[md_file]
        )

        # Add examples
        gr.Markdown("### ğŸ“š Example Images")
        gr.Examples(
            examples=[
                ["example_document.jpg", "Markdown Conversion", "", "Gundam (Recommended)"],
                ["example_receipt.jpg", "Free OCR", "", "Small"],
            ],
            inputs=[image_input, prompt_type, custom_prompt, model_size],
            outputs=[output_text],
            fn=process_image,
            cache_examples=False,
        )

        gr.Markdown(
            """
            ---
            ### â„¹ï¸ About

            This demo uses [DeepSeek-OCR](https://huggingface.co/deepseek-ai/DeepSeek-OCR) for optical character recognition.

            **Model Sizes Explained:**
            - **Tiny**: Fastest, lowest accuracy (512x512)
            - **Small**: Fast, good for simple documents (640x640)
            - **Base**: Balanced performance (1024x1024)
            - **Large**: High accuracy, slower (1280x1280)
            - **Gundam (Recommended)**: Balanced config with crop mode for complex docs
            """
        )

    return demo


if __name__ == "__main__":
    demo = create_demo()
    # å…è®¸æœ¬åœ°è®¿é—®ï¼Œå¯æŒ‰éœ€ä¿®æ”¹ server_name/port
    demo.launch(server_name="0.0.0.0", server_port=2714, share=False)
